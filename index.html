<!DOCTYPE html>
<html lang="en">
<head>

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no" />
<meta name="author" content="原豪" />


    
    


<meta name="description" content="记录我的点点滴滴">
<meta property="og:type" content="website">
<meta property="og:title" content="原豪的个人博客">
<meta property="og:url" content="http://yuanhao.space/index.html">
<meta property="og:site_name" content="原豪的个人博客">
<meta property="og:description" content="记录我的点点滴滴">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="原豪的个人博客">
<meta name="twitter:description" content="记录我的点点滴滴">

<link rel="apple-touch-icon" href= "/apple-touch-icon.png">


    <link rel="alternative" href="/atom.xml" title="原豪的个人博客" type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">


<link rel="stylesheet" href="/css/style.css">


    <style> .article { opacity: 0;} </style>


<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>原豪的个人博客</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: true,
        isPost: false,
        isArchive: false,
        isTag: false,
        isCategory: false,
        open_in_new: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: undefined
    }
</script>


    <script> yiliaConfig.jquery_ui = [false]; </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/avatar.png" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">原豪</a></h1>
        </hgroup>

        

        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>Menu</li>
                        <li>Tags</li>
                        
                        <li>Friends</li>
                        
                        
                        <li>About Me</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">主页</a></li>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                            <li><a href="/tags/">标签云</a></li>
                        
                            <li><a href="/about/">关于我</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="mailto:153516796@qq.com" title="Email"></a>
                            
                                <a class="fa GitHub" target="_blank" href="#" title="GitHub"></a>
                            
                                <a class="fa RSS" target="_blank" href="/atom.xml" title="RSS"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CentOS-7-运行级别/">CentOS 7, 运行级别</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HBase/">HBase</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nutch/">Nutch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VMware网卡问题/">VMware网卡问题</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/centos7-eclipse/">centos7 eclipse</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hadoop-2-7-2-前期准备/">hadoop 2.7.2 前期准备</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hadoop-2-7-2-集群-7台/">hadoop 2.7.2 集群 7台</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/">spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark安装/">spark安装</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sqoop/">sqoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/伪分布式/">伪分布式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/编译Hadoop-CentOS-7/">编译Hadoop CentOS 7</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a target="_blank" class="main-nav-link switch-friends-link" href="https://hexo.io">Hexo</a>
                    
                      <a target="_blank" class="main-nav-link switch-friends-link" href="https://pages.github.com/">GitHub</a>
                    
                      <a target="_blank" class="main-nav-link switch-friends-link" href="http://yuanhao.space/">MOxFIVE</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">专注与大数据</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">原豪</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/avatar.png" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">原豪</a></h1>
            </hgroup>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">主页</a></li>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/tags/">标签云</a></li>
                
                    <li><a href="/about/">关于我</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="mailto:153516796@qq.com" title="Email"></a>
                            
                                <a class="fa GitHub" target="_blank" href="#" title="GitHub"></a>
                            
                                <a class="fa RSS" target="_blank" href="/atom.xml" title="RSS"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="Tags" friends="Friends" about="About Me"/>
</nav>
      <div class="body-wrap">
  
    <article id="post-Nutch简介" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/07/03/Nutch简介/" class="article-date">
      <time datetime="2016-07-03T06:52:30.000Z" itemprop="datePublished">2016-07-03</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/07/03/Nutch简介/">Nutch简介</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>Nutch作为当今最流行的开源爬虫之一，已被企业广泛使用。Nutch的插件机制使得开发者可以灵活地定制网页抓取策略。Nutch有着悠久的历史，当今大名鼎鼎的Hadoop就是由Nutch发展而来。Nutch不仅可以运行在单机模式下，还可以运行在分布式模式下。</p>
<h2 id="1-认识Nutch"><a href="#1-认识Nutch" class="headerlink" title="1 认识Nutch"></a>1 认识Nutch</h2><p>目前Nutch分为两个大版本1.x和2.x，Apache分别对这两个大版本进行独立开发和维护。其中，1.x和2.x最大的不同点在于，1.x是基于hadoop的HDFS文件系统的，而2.x将数据的存储层抽象出来，可以将数据保存在Hbase、MySQL等数据库中。还有一点很重要，Nutch在1.2以及之前，都是作为一个完整的搜索引擎进行发布的，而从1.3开始，Nutch本身就主要只有爬虫功能，若需要对抓取的数据建立索引并进行搜索，还要用到Solr全文检索服务器。由于Nutch和Solr都是基于Lucene开发的，因此Nutch抓取的数据可以轻松地在Solr中建立索引。Nutch官网可以下载到编译好的1.x包，但2.x只提供源码，需要自己编译。Nutch使用Ant来构建的，若自己编译的话，需要安装Ant来编译源码。</p>
<p>对于如何选择Nutch的版本，主要考虑一下以下问题：如果只需要抓取少量的网站，并对其建立索引，使用1.x和2.x都可以，甚至都可以使用单机的，而不需分布式。但如果要抓取大量网站，甚至是全网爬行，那么最好选择1.x，并且采用分布式，因为1.x是基于hadoop文件系统的，而hadoop又是专门为处理大数据而生。若抓取大量网站时采用2.x，可能会遇到一些性能问题，要是使用MySQL来存储数据，网页数据上百亿时，性能将是一个噩梦。</p>
<p>Nutch1.x不同的版本变化也比较大，执行命令发生过较大改变，因此，建议初学者下载本教程对应的版本1.10，等到熟悉使用Nutch的时候，那些改变对你而言就没太大影响了。</p>
<p>Nutch作为当今最流行的开源爬虫之一，已被企业广泛使用。Nutch的插件机制使得开发者可以灵活地定制网页抓取策略。Nutch有着悠久的历史，当今大名鼎鼎的Hadoop就是由Nutch发展而来。Nutch不仅可以运行在单机模式下，还可以运行在分布式模式下。</p>
<h2 id="2-Nutch工作环境"><a href="#2-Nutch工作环境" class="headerlink" title="2 Nutch工作环境"></a>2 Nutch工作环境</h2><p>Nutch仅支持在Linux环境下工作，若要在Windows操作系统中使用Nutch，需要安装Cygwin。Cygwin是在Windows下模拟Linux操作系统的软件，它并非一个实际的操作系统。</p>
<p>最新版的Nutch 1.10需要JDK7运行环境，当然也可以使用最新版的JDK8。</p>
<p>若需要配置分布式运行环境，还需要下载hadoop-1.2.0的版本。Hadoop的历史版本下载地址为<a href="http://archive.apache.org/dist/hadoop/core/" target="_blank" rel="external">http://archive.apache.org/dist/hadoop/core/</a>。</p>
<p>本教程将演示编译Nutch源码的过程，因此还需要安装Ant。</p>
<h2 id="3-下载Nutch"><a href="#3-下载Nutch" class="headerlink" title="3 下载Nutch"></a>3 下载Nutch</h2><pre><code>在Nutch的官方网站[http://nutch.apache.org/downloads.html](http://nutch.apache.org/downloads.html)可以下载到最新版的Nutch，若需要下载历史版本，请在这里下载[http://archive.apache.org/dist/nutch/](http://archive.apache.org/dist/nutch/)。本教程下载的包为apache-nutch-1.10-src.zip，它是一个源码包，需要我们自己编译，具体的编译过程在后续教程中详细讲解。
</code></pre>
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Nutch/">Nutch</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-spark-1.6.2 源码编译" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/06/29/spark-1.6.2 源码编译/" class="article-date">
      <time datetime="2016-06-29T08:22:48.000Z" itemprop="datePublished">2016-06-29</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/06/29/spark-1.6.2 源码编译/">spark-1.6.2 源码编译</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h2 id="一、安装maven"><a href="#一、安装maven" class="headerlink" title="一、安装maven"></a>一、安装maven</h2><hr>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.安装maven  tar -zxvf /opt/modules/apache/maven/apache-maven-3.3.9-bin.tar.gz  -C  /opt/modules/apache/maven/   即:$MAVEN_HOME=/opt/modules/apache/maven//opt/modules/apache/maven/apache-maven-3.3.9</span><br><span class="line">2.设置环境变量 </span><br><span class="line">    #设置MAVEN</span><br><span class="line">    export MAVEN_HOME=/opt/modules/apache/maven/apache-maven-3.3.9</span><br><span class="line">    # PATH 汇总</span><br><span class="line">    export PATH=$JAVA_HOME/bin:$MAVEN_HOME/bin:$PATH</span><br><span class="line">3.验证maven安装  mvn -v  会输出mavne的版本信息</span><br></pre></td></tr></table></figure>
<h2 id="二、用maven安装spark"><a href="#二、用maven安装spark" class="headerlink" title="二、用maven安装spark"></a>二、用maven安装spark</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. 解压软件包  tar -zxvf spark-1.6.0.tgz -C /opt/modules/bigdata/spark  即  $SPARK_HOME=/opt/modules/bigdata/spark/spark-1.6.0</span><br><span class="line">2. cd  $SPARK_HOME</span><br><span class="line">3.防止maven内溢出:export MAVEN_OPTS=&quot;-Xms256m -Xmx512m&quot;</span><br><span class="line">4.执行 apaven安装   mvn -Dhadoop.version=2.7.1 -Phadoop-2.6 -DskipTests clean package</span><br></pre></td></tr></table></figure>
<h2 id="三、官网详细说明"><a href="#三、官网详细说明" class="headerlink" title="三、官网详细说明"></a>三、官网详细说明</h2><p><a href="http://spark.apache.org/docs/latest/building-spark.html" target="_blank" rel="external">http://spark.apache.org/docs/latest/building-spark.html</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/">spark</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-spark-1.6.2-bin-hadoop2.6-安装" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/06/29/spark-1.6.2-bin-hadoop2.6-安装/" class="article-date">
      <time datetime="2016-06-29T08:22:48.000Z" itemprop="datePublished">2016-06-29</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/06/29/spark-1.6.2-bin-hadoop2.6-安装/">spark-1.6.2-bin-hadoop2.6-安装</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><ul>
<li><p>安装好hadoop集群</p>
<p><a href="http://yuanhao.space/2016/06/12/hadoop%202.7.2%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%20%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E7%A8%8B%EF%BC%887%E5%8F%B0%EF%BC%89/">点击进入hadoop集群安装链接</a></p>
</li>
<li><p>安装好scala</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scala-2.10.6 版本</span><br></pre></td></tr></table></figure>
</li>
<li><p>spark安装包</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-1.6.0-bin-hadoop2.6.tgz</span><br></pre></td></tr></table></figure>
</li>
<li><p>centos7 操作系统 桌面版</p>
</li>
</ul>
<h3 id="集群环境如下"><a href="#集群环境如下" class="headerlink" title="集群环境如下"></a>集群环境如下</h3><ul>
<li><p>s0为master主控制节</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">192.168.1.110 spark0</span><br><span class="line">192.168.1.111 spark1</span><br><span class="line">192.168.1.112 spark2</span><br><span class="line">192.168.1.113 spark3</span><br><span class="line">192.168.1.114 spark4</span><br></pre></td></tr></table></figure>
</li>
<li><p>集群配置说明</p>
<p>先在spark0上配置完成所有配置信息，然后同步到所有集群每一个节点上，所有配置包括安装路径是一样的</p>
</li>
</ul>
<h2 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a>操作步骤</h2><ul>
<li><p>解压安装包</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf   spark-1.6.20-bin-hadoop2.6.tgz  -C    /opt/modules/bigdata/spark   即：$SPARK_HOME=/opt/modules/bigdata/spark/spark-1.6.2-bin-hadoop2.6</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><ul>
<li><p>$SPARK_HOME/conf/spark-env.sh</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">复制$SPARK_HOME/conf/spark-env.sh.template 为 $SPARK_HOME/conf/spark-env.sh</span><br><span class="line"></span><br><span class="line">修改$SPARK_HOME/conf/spark-env.sh 增加</span><br><span class="line"></span><br><span class="line"> export    JAVA_HOME=/opt/modules/environment/jdk/jdk1.8.0_65</span><br><span class="line"> export    SCALA_HOME=/opt/modules/environment/scala/scala-2.10.6</span><br><span class="line"> export     HADOOP_HOME=/opt/modules/bigdata/hadoop/hadoop-2.6.0</span><br><span class="line"> export     HADOOP_CONF_DIR=/opt/modules/bigdata/hadoop/hadoop-2.6.0/etc/hadoop</span><br><span class="line"> export     SPARK_MASTER_IP=s0</span><br><span class="line"> export      SPARK_WORKER_MEMORY=1500M</span><br><span class="line"> export      SPARK_EXECUTOR_MEMORY=1500m</span><br><span class="line"> export      SPARK_DRIVER_MEMORY=1500m</span><br><span class="line"> export      SPARK_WORKER_CORES=2</span><br></pre></td></tr></table></figure>
</li>
<li><p>cp $SPARK_HOME/conf/slaves.template $SPARK_HOME/conf/slaves 在末尾增加</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">spark0</span><br><span class="line">spark1</span><br><span class="line">spark2</span><br><span class="line">spark3</span><br></pre></td></tr></table></figure>
</li>
<li><p>cp $SPARK_HOME/conf/spark-defaults.conf.template $SPARK_HOME/conf/spark-defaults.conf</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">spark.executor.extraJavaOptions          -XX:+PrintGCDetails -Dkey=value -Dnumbers=&quot;one two three&quot;</span><br><span class="line">spark.eventLog.enabled                     true</span><br><span class="line">spark.eventLog.dir                          hdfs://spark0:9000/historyserverforSpark</span><br><span class="line">spark.yarn.historyServer.address          s0:18080</span><br><span class="line">spark.history.fs.logDirectory             hdfs://spark0:9000/historyserverforSpark</span><br><span class="line">#spark.default.parallelism                 100</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动spark</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$SPARK_HOME/sbin/start-all.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>关闭spark</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$SPARK_HOME/sbin/stop-all.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动历史记录服务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$SPARK_HOME/sbin/start-history-server.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>关闭历史记录服务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$SPARK_HOME/sbin/stop-history-server.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>访问界面</p>
<p>访问 <a href="http://spark20:8080/" target="_blank" rel="external">http://Spark20:8080</a> 访问 <a href="http://spark20:18080/" target="_blank" rel="external">http://Spark20:18080</a></p>
<p><img src="https://opensourceteam.gitbooks.io/bigdata/content/spark/install/spark_master.png" alt="![](spark_master.png)"><img src="https://opensourceteam.gitbooks.io/bigdata/content/spark/install/spark_history_server.png" alt="img"></p>
</li>
<li><p>提交并行计算</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$SPARK_HOME/bin/spark-submit  --class org.apache.spark.examples.SparkPi  --master spark://s0:7077  ../lib/spark-examples-1.6.2-hadoop2.6.0.jar  1000</span><br></pre></td></tr></table></figure>
</li>
<li><p>连接客户端工具 Shell</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$SPARK_HOME/bin/spark-shell  --master spark://s0:7077</span><br></pre></td></tr></table></figure>
</li>
<li><p>统计单词数量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sc.textFile(&quot;/library/wordcount/input/Data&quot;).flatMap(_.split(&quot; &quot;)).map(word =&gt; (word,1)).reduceByKey(_+_).map(pair =&gt; (pair._2,pair._1)).sortByKey(false).map(pair =&gt; (pair._2,pair._1)).saveAsTextFile(&quot;/library/wordcount/output/spark_word_count&quot;) ](http://spark.apache.org/docs/latest/building-spark.html)</span><br></pre></td></tr></table></figure></li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark安装/">spark安装</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-hadoop 2.7.2伪分布式" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/06/29/hadoop 2.7.2伪分布式/" class="article-date">
      <time datetime="2016-06-29T06:52:30.000Z" itemprop="datePublished">2016-06-29</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/06/29/hadoop 2.7.2伪分布式/">hadoop 2.7.2伪分布式</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>1.准备Linux环境</p>
<pre><code>1.0点击VMware快捷方式，右键打开文件所在位置 -&gt; 双击vmnetcfg.exe -&gt; VMnet1 host-only -&gt;修改subnet ip 设置网段：192.168.1.0 子网掩码：255.255.255.0 -&gt; apply -&gt; ok
    回到windows --&gt; 打开网络和共享中心 -&gt; 更改适配器设置 -&gt; 右键VMnet1 -&gt; 属性 -&gt; 双击IPv4 -&gt; 设置windows的IP：192.168.1.100 子网掩码：255.255.255.0 -&gt; 点击确定
    在虚拟软件上 --My Computer -&gt; 选中虚拟机 -&gt; 右键 -&gt; settings -&gt; network adapter -&gt; host only -&gt; ok    
1.1修改主机名
    vim /etc/sysconfig/network

    NETWORKING=yes
    HOSTNAME=yun01    ###

1.2修改IP
    两种方式：
    第一种：通过Linux图形界面进行修改（强烈推荐）
        进入Linux图形界面 -&gt; 右键点击右上方的两个小电脑 -&gt; 点击Edit connections -&gt; 选中当前网络System eth0 -&gt; 点击edit按钮 -&gt; 选择IPv4 -&gt; method选择为manual -&gt; 点击add按钮 -&gt; 添加IP：192.168.1.101 子网掩码：255.255.255.0 网关：192.168.1.1 -&gt; apply

    第二种：修改配置文件方式（潘砍绦蛟匙ㄓ茫�
        vim /etc/sysconfig/network-scripts/ifcfg-eth0

        DEVICE=&quot;eth0&quot;
        BOOTPROTO=&quot;static&quot;               ###
        HWADDR=&quot;00:0C:29:3C:BF:E7&quot;
        IPV6INIT=&quot;yes&quot;
        NM_CONTROLLED=&quot;yes&quot;
        ONBOOT=&quot;yes&quot;
        TYPE=&quot;Ethernet&quot;
        UUID=&quot;ce22eeca-ecde-4536-8cc2-ef0dc36d4a8c&quot;
        IPADDR=&quot;192.168.1.101&quot;           ###
        NETMASK=&quot;255.255.255.0&quot;          ###
        GATEWAY=&quot;192.168.1.1&quot;            ###

1.3修改主机名和IP的映射关系
    vim /etc/hosts

    192.168.1.101    yun01

1.4关闭防火墙
    #查看防火墙状态
    service iptables status
    #关闭防火墙
    service iptables stop
    #查看防火墙开机启动状态
    chkconfig iptables --list
    #关闭防火墙开机启动
    chkconfig iptables off

1.5重启Linux
    reboot
</code></pre><p>2.安装JDK<br>    2.1上传alt+p 后出现sftp窗口，然后put d:\xxx\yy\ll\jdk-7u_65-i585.tar.gz</p>
<pre><code>2.2解压jdk
    #创建文件夹
    mkdir /home/hadoop/app
    #解压
    tar -zxvf jdk-7u55-linux-i586.tar.gz -C /home/hadoop/app

2.3将java添加到环境变量中
    vim /etc/profile
    #在文件最后添加
    export JAVA_HOME=/home/hadoop/app/jdk-7u_65-i585
    export PATH=$PATH:$JAVA_HOME/bin

    #刷新配置
    source /etc/profile
</code></pre><p>3.安装hadoop2.4.1<br>    先上传hadoop的安装包到服务器上去/home/hadoop/<br>    注意：hadoop2.x的配置文件$HADOOP_HOME/etc/hadoop<br>    伪分布式需要修改5个配置文件<br>    3.1配置hadoop<br>    第一个：hadoop-env.sh<br>        vim hadoop-env.sh</p>
<pre><code>    #第27行
    export JAVA_HOME=/usr/java/jdk1.7.0_65

第二个：core-site.xml

    &lt;!-- 指定HADOOP所使用的文件系统schema（URI），HDFS的老大（NameNode）的地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://yun01:9000&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
        &lt;value&gt;/home/hadoop/hadoop-2.7.2/tmp&lt;/value&gt;
&lt;/property&gt;

第三个：hdfs-site.xml   hdfs-default.xml  (3)
    &lt;!-- 指定HDFS副本的数量 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;1&lt;/value&gt;
&lt;/property&gt;

第四个：mapred-site.xml (mv mapred-site.xml.template mapred-site.xml)
    mv mapred-site.xml.template mapred-site.xml
    vim mapred-site.xml
    &lt;!-- 指定mr运行在yarn上 --&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;

第五个：yarn-site.xml
    &lt;!-- 指定YARN的老大（ResourceManager）的地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
        &lt;value&gt;yun01&lt;/value&gt;
&lt;/property&gt;
    &lt;!-- reducer获取数据的方式 --&gt;
&lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
 &lt;/property&gt;

3.2将hadoop添加到环境变量

vim /etc/proflie
    export JAVA_HOME=/usr/java/jdk1.7.0_65
    export HADOOP_HOME=/itcast/hadoop-2.7.2
    export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

source /etc/profile

3.3格式化namenode（是对namenode进行初始化）
    hdfs namenode -format (hadoop namenode -format)

3.4启动hadoop
    先启动HDFS
    sbin/start-dfs.sh

    再启动YARN
    sbin/start-yarn.sh

3.5验证是否启动成功
    使用jps命令验证
    27408 NameNode
    28218 Jps
    27643 SecondaryNameNode
    28066 NodeManager
    27803 ResourceManager
    27512 DataNode

    http://192.168.1.101:50070 （HDFS管理界面）
    http://192.168.1.101:8088 （MR管理界面）
</code></pre><p>4.配置ssh免登陆</p>
<pre><code>#生成ssh免登陆密钥
#进入到我的home目录
cd ~/.ssh

ssh-keygen -t rsa （四个回车）
执行完这个命令后，会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）
将公钥拷贝到要免登陆的机器上
ssh-copy-id localhost
</code></pre>
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/伪分布式/">伪分布式</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-centos 7 安装 eclipse" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/06/28/centos 7 安装 eclipse/" class="article-date">
      <time datetime="2016-06-28T05:24:30.000Z" itemprop="datePublished">2016-06-28</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/06/28/centos 7 安装 eclipse/">centos7 安装 eclipse</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h2 id="centos7-安装-eclipse"><a href="#centos7-安装-eclipse" class="headerlink" title="centos7 安装 eclipse"></a>centos7 安装 eclipse</h2><p>Eclipse是一个集成开发环境（IDE），包含一个基工作区和定制环境的可扩展插件系统。大部分使用 Java 编写，Eclipse 可以用来开发应用程序。通过各种插件，Eclipse 也可以用于其他编程语言开发应用程序：Ada、ABAP、C、C++、COBOL、 Fortran、Haskell、 JavaScript、Lasso、Natural、Perl、 PHP、 Prolog、 Python、Ruby、Scala、Clojure、 Groovy、Scheme 和 Erlang。它也可以用来开发Mathematica软件包。开发环境包括 Eclipse Java 开发工具（JDT）支持 Java与Scala，Eclipse CDT C / C + +和Eclipse PDT PHP，等等。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="1、安装java"><a href="#1、安装java" class="headerlink" title="1、安装java"></a>1、安装java</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install java</span><br></pre></td></tr></table></figure>
<p>yum （全称为 <code>Yellow dog Updater, Modified</code>),能够从指定的服务器自动下载gz包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。yum提供了查找、安装、删除某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。</p>
<p>yum （全称为 <code>Yellow dog Updater, Modified</code>),能够从指定的服务器自动下载gz包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。yum提供了查找、安装、删除某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。<br>yum的命令形式一般是如下：<code>yum [options] [command] [package ...]</code></p>
<p>yum （全称为 <code>Yellow dog Updater, Modified</code>),能够从指定的服务器自动下载gz包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。yum提供了查找、安装、删除某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。<br>yum的命令形式一般是如下：<code>yum [options] [command] [package ...]</code><br>其中的[options]是可选的，选项包括-h（帮助），-y（当安装过程提示选择全部为”yes”），-q（不显示安装的过程）等等。[command]为所要进行的操作，[package …]是操作的对象。</p>
<p>yum （全称为 <code>Yellow dog Updater, Modified</code>),能够从指定的服务器自动下载gz包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。yum提供了查找、安装、删除某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。<br>yum的命令形式一般是如下：<code>yum [options] [command] [package ...]</code><br>其中的[options]是可选的，选项包括-h（帮助），-y（当安装过程提示选择全部为”yes”），-q（不显示安装的过程）等等。[command]为所要进行的操作，[package …]是操作的对象。<br>yum 是linux系统的自动安装系统</p>
<p>yum （全称为 <code>Yellow dog Updater, Modified</code>),能够从指定的服务器自动下载gz包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。yum提供了查找、安装、删除某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。<br>yum的命令形式一般是如下：<code>yum [options] [command] [package ...]</code><br>其中的[options]是可选的，选项包括-h（帮助），-y（当安装过程提示选择全部为”yes”），-q（不显示安装的过程）等等。[command]为所要进行的操作，[package …]是操作的对象。<br>yum 是linux系统的自动安装系统<br>yum install 仅安装指定的软件</p>
<h3 id="2、检查java版本"><a href="#2、检查java版本" class="headerlink" title="2、检查java版本"></a>2、检查java版本</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">java -version</span><br><span class="line"></span><br><span class="line">java version &quot;1.7.0_51&quot;</span><br><span class="line">OpenJDK Runtime Environment (rhel-2.4.5.5.el7-x86_64 u51-b31)</span><br><span class="line">OpenJDK 64-Bit Server VM (build 24.51-b03, mixed mode)</span><br></pre></td></tr></table></figure>
<p>java -version 查看java的版本</p>
<h3 id="3、下载eclipse-luna版压缩包并解压"><a href="#3、下载eclipse-luna版压缩包并解压" class="headerlink" title="3、下载eclipse-luna版压缩包并解压"></a>3、下载eclipse-luna版压缩包并解压</h3><p>下载地址<a href="http://www.eclipse.org/downloads/download.php?file=/technology/epp/downloads/release/luna/SR2/eclipse-java-luna-SR2-linux-gtk-x86_64.tar.gz" target="_blank" rel="external">http://www.eclipse.org/downloads/download.php?file=/technology/epp/dow…</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">解压到/opt 目录下</span><br><span class="line">tar -zxvf eclipse-java-luna-SR1-linux-gtk-x86_64.tar.gz -C /opt</span><br></pre></td></tr></table></figure>
<p><code>/opt 表示解压到/opt目录下，加了-C,后面要添加路径</code></p>
<h3 id="4、使用符号连接目录"><a href="#4、使用符号连接目录" class="headerlink" title="4、使用符号连接目录"></a>4、使用符号连接目录</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ln -s /opt/eclipse/eclipse /usr/bin/eclipse  </span><br><span class="line">eclipse与/usr之间有空格</span><br></pre></td></tr></table></figure>
<p><code>注意</code></p>
<p><code>注意</code><br><strong>符号链接的用法 ln -s 源文件 目标文件 ，-s 是符号的意思（symbolic）软连接</strong></p>
<p><code>注意</code><br><strong>符号链接的用法 ln -s 源文件 目标文件 ，-s 是符号的意思（symbolic）软连接</strong><br>符号链接是通过创建一个特殊的类型的文件来起作用，它只会在你选定的位置上生成一个文件的镜像，它的功能是为某一个文件在另外一个位置建立一个同步的链接.当我们需要在不同的目录，用到相同的文件时，我们不需要在每一个需要的目录下都放一个必须相同的文件，我们只要在某个固定的目录，放上该文件，然后在 其它的目录下用ln命令链接（link）它就可以，不必重复的占用磁盘空间。跟windows下的快捷键差不多，这样不用在终端敲指令就可以实现打开软件。</p>
<p><code>注意</code><br><strong>符号链接的用法 ln -s 源文件 目标文件 ，-s 是符号的意思（symbolic）软连接</strong><br>符号链接是通过创建一个特殊的类型的文件来起作用，它只会在你选定的位置上生成一个文件的镜像，它的功能是为某一个文件在另外一个位置建立一个同步的链接.当我们需要在不同的目录，用到相同的文件时，我们不需要在每一个需要的目录下都放一个必须相同的文件，我们只要在某个固定的目录，放上该文件，然后在 其它的目录下用ln命令链接（link）它就可以，不必重复的占用磁盘空间。跟windows下的快捷键差不多，这样不用在终端敲指令就可以实现打开软件。<br>如果你用ls察看一个目录时，发现有的文件后面有一个@的符号，那就是一个用ln命令生成的文件，用ls -l命令去察看，就可以看到显示的link的路径了</p>
<p>命令的意思是，在/usr/bin/eclipse 目录下创建一个同步连接，而源文件在/opt/eclipse/eclipse目录下</p>
<h3 id="5、-创建一个桌面启动器"><a href="#5、-创建一个桌面启动器" class="headerlink" title="5、 创建一个桌面启动器"></a>5、 创建一个桌面启动器</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /usr/share/applications/eclipse.desktop</span><br></pre></td></tr></table></figure>
<p>vi 打开后是一个新的file</p>
<p>添加如下代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[Desktop Entry]</span><br><span class="line">Encoding=UTF-8</span><br><span class="line">Name=Eclipse 4.4.1</span><br><span class="line">Comment=Eclipse Luna</span><br><span class="line">Exec=/usr/bin/eclipse</span><br><span class="line">Icon=/opt/eclipse/icon.xpm</span><br><span class="line">Categories=Application;Development;Java;IDE</span><br><span class="line">Version=1.0</span><br><span class="line">Type=Application</span><br><span class="line">Terminal=0</span><br></pre></td></tr></table></figure>
<p>上面是将eclipse显示在centos的应用程序上，并对其进行描述，比如编码方式，命名，显示的图标，版本，类型</p>
<h3 id="6、检查eclipse是否被添加到应用程序"><a href="#6、检查eclipse是否被添加到应用程序" class="headerlink" title="6、检查eclipse是否被添加到应用程序"></a>6、检查eclipse是否被添加到应用程序</h3><p><img src="https://segmentfault.com/img/bVlh0F" alt="img"></p>
<p>运行eclipse</p>
<p><img src="https://segmentfault.com/img/bVlh0G" alt="img"></p>
<p>完成！！！</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/centos7-eclipse/">centos7 eclipse</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-CentOS 7 修改默认运行级别" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/06/26/CentOS 7 修改默认运行级别/" class="article-date">
      <time datetime="2016-06-26T11:50:29.000Z" itemprop="datePublished">2016-06-26</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/06/26/CentOS 7 修改默认运行级别/">CentOS 7 修改默认运行级别</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>在虚拟机新安装了个CentOS 7，图形界面启动太慢，想调整一下按照以前的经验改运行级别，输入：</p>
<p><strong>vi /etc/inittab</strong></p>
<p>然后发现跟CentOS 6.x不一样了，在CentOS 6.x inittab设置不再生效：</p>
<p>inittab文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># inittab is no longer used when using systemd.</span><br><span class="line">#</span><br><span class="line"># ADDING CONFIGURATION HERE WILL HAVE NO EFFECT ON YOUR SYSTEM.</span><br><span class="line">#</span><br><span class="line"># Ctrl-Alt-Delete is handled by /usr/lib/systemd/system/ctrl-alt-del.target</span><br><span class="line">#</span><br><span class="line"># systemd uses &apos;targets&apos; instead of runlevels. By default, there are two main targets:</span><br><span class="line">#</span><br><span class="line"># multi-user.target: analogous to runlevel 3</span><br><span class="line"># graphical.target: analogous to runlevel 5</span><br><span class="line">#</span><br><span class="line"># To view current default target, run:</span><br><span class="line"># systemctl get-default</span><br><span class="line">#</span><br><span class="line"># To set a default target, run:</span><br><span class="line"># systemctl set-default TARGET.target</span><br><span class="line">#</span><br></pre></td></tr></table></figure>
<p>仔细读一下上面的提示<br>multi-user.target 类似与之前的runlevel 3<br>graphical.target 类似与之前的runlevel 5</p>
<p>按照上面的提示，查看当前的默认target输入命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# systemctl get-default</span><br><span class="line">graphical.target</span><br><span class="line">[root@localhost ~]# </span><br><span class="line">当前为graphical.target</span><br></pre></td></tr></table></figure>
<p>修改为命令模式multi-user.target：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# systemctl set-default multi-user.target</span><br><span class="line">rm &apos;/etc/systemd/system/default.target&apos;</span><br><span class="line">ln -s &apos;/usr/lib/systemd/system/multi-user.target&apos; &apos;/etc/systemd/system/default.target&apos;</span><br><span class="line">[root@localhost ~]#</span><br></pre></td></tr></table></figure>
<p>查看一下当前，发现得到预期要求：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# systemctl get-default</span><br><span class="line">multi-user.target</span><br><span class="line">[root@localhost ~]#</span><br></pre></td></tr></table></figure>
<p>最后重启发现，果然是命令模式~~</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CentOS-7-运行级别/">CentOS 7, 运行级别</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-HBase集群搭建" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/06/24/HBase集群搭建/" class="article-date">
      <time datetime="2016-06-24T14:52:30.000Z" itemprop="datePublished">2016-06-24</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/06/24/HBase集群搭建/">HBase集群搭建</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>1.上传hbase安装包</p>
<p>2.解压</p>
<p>3.配置hbase集群，要修改3个文件（首先zk集群已经安装好了）<br>    注意：要把hadoop的hdfs-site.xml和core-site.xml 放到hbase/conf下</p>
<pre><code>3.1修改hbase-env.sh
export JAVA_HOME=/usr/java/jdk1.7.0_55
//告诉hbase使用外部的zk 
export HBASE_MANAGES_ZK=false

vim hbase-site.xml
&lt;configuration&gt;
    &lt;!-- 指定hbase在HDFS上存储的路径 --&gt;
    &lt;property&gt;
            &lt;name&gt;hbase.rootdir&lt;/name&gt;
            &lt;value&gt;hdfs://ns1/hbase&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 指定hbase是分布式的 --&gt;
    &lt;property&gt;
            &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
            &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 指定zk的地址，多个用“,”分割 --&gt;
    &lt;property&gt;
            &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
            &lt;value&gt;yun05:2181,yun06:2181,yun07:2181&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;

vim regionservers
yun05
yun06
yun07

3.2拷贝hbase到其他节点
    scp -r /hadoop/hbase-0.96.2-hadoop2/ yun02:/hadoop/
    scp -r /hadoop/hbase-0.96.2-hadoop2/ yun03:/hadoop/
    scp -r /hadoop/hbase-0.96.2-hadoop2/ yun04:/hadoop/
    scp -r /hadoop/hbase-0.96.2-hadoop2/ yun05:/hadoop/
    scp -r /hadoop/hbase-0.96.2-hadoop2/ yun06:/hadoop/
</code></pre><p>4.将配置好的HBase拷贝到每一个节点并同步时间。</p>
<p>5.启动所有的hbase<br>    分别启动zk<br>        ./zkServer.sh start<br>    启动hbase集群<br>        start-dfs.sh<br>    启动hbase，在主节点上运行：<br>        start-hbase.sh<br>6.通过浏览器访问hbase管理页面<br>    192.168.1.201:60010<br>7.为保证集群的可靠性，要启动多个HMaster<br>    hbase-daemon.sh start master</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HBase/">HBase</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-详解Sqoop的架构和安装部署" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/06/23/详解Sqoop的架构和安装部署/" class="article-date">
      <time datetime="2016-06-23T11:32:10.000Z" itemprop="datePublished">2016-06-23</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/06/23/详解Sqoop的架构和安装部署/">详解Sqoop的架构和安装部署</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h2 id="Sqoop是什么"><a href="#Sqoop是什么" class="headerlink" title="Sqoop是什么"></a>Sqoop是什么</h2><p>Sqoop 是连接传统关系型数据库和 Hadoop 的桥梁。它包括以下两个方面：<br>　　1、 将关系型数据库的数据导入到 Hadoop 及其相关的系统中，如 Hive和HBase。<br>　　2、 将数据从 Hadoop 系统里抽取并导出到关系型数据库。<br>Sqoop 的核心设计思想是利用 MapReduce 加快数据传输速度。也就是说 Sqoop 的导入和导出功能是通过 MapReduce 作业实现的。所以它是一种批处理方式进行数据传输，难以实现实时的数据进行导入和导出。</p>
<h2 id="为什么选择Sqoop"><a href="#为什么选择Sqoop" class="headerlink" title="为什么选择Sqoop"></a>为什么选择Sqoop</h2><p>我们为什么选择 Sqoop 呢？通常基于三个方面的考虑：<br>　　1、它可以高效、可控地利用资源，可以通过调整任务数来控制任务的并发度。另外它还可以配置数据库的访问时间等等。<br>　　 2、它可以自动的完成数据类型映射与转换。我们往往导入的数据是有类型的，它可以自动根据数据库中的类型转换到 Hadoop 中，当然用户也可以自定义它们之间的映射关系。<br>　　 3、它支持多种数据库，比如，<a href="http://lib.csdn.net/base/14" target="_blank" rel="external">MySQL</a>、Oracle和PostgreSQL等等数据库。</p>
<h2 id="Sqoop-架构与常用操作"><a href="#Sqoop-架构与常用操作" class="headerlink" title="Sqoop 架构与常用操作"></a>Sqoop 架构与常用操作</h2><p>Sqoop 架构是非常简单的，它主要由三个部分组成：Sqoop client、HDFS/HBase/Hive、Database。下面我们来看一下 Sqoop 的架构图。 </p>
<p><img src="http://a1.qpic.cn/psb?/V11T2YKt1pMnWZ/X0rvkMDlhn*afoHXx.l82uAAj.R5XSbz94vcx4k.nVY!/b/dK4AAAAAAAAA&amp;bo=5wLwAQAAAAADBzY!&amp;rf=viewer_4" alt=""></p>
<p>用户向 Sqoop 发起一个命令之后，这个命令会转换为一个基于 Map Task 的 MapReduce 作业。Map Task 会访问数据库的元数据信息，通过并行的 Map Task 将数据库的数据读取出来，然后导入 Hadoop 中。 当然也可以将 Hadoop 中的数据，导入传统的关系型数据库中。它的核心思想就是通过基于 Map Task （只有 map）的 MapReduce 作业，实现数据的并发拷贝和传输，这样可以大大提高效率。</p>
<h3 id="Sqoop与HDFS结合"><a href="#Sqoop与HDFS结合" class="headerlink" title="Sqoop与HDFS结合"></a>Sqoop与HDFS结合</h3><p>结合 HDFS，介绍 Sqoop 从关系型数据库的导入和导出。 </p>
<p><strong>Sqoop import</strong><br>　　它的功能是将数据从关系型数据库导入 HDFS 中，其流程图如下所示。</p>
<p><img src="http://a1.qpic.cn/psb?/V11T2YKt1pMnWZ/XxQj3oyTwIdqh25bq0d7wf7c3Ouh3bAKDesHK63SalQ!/b/dKUAAAAAAAAA&amp;bo=wAGcAQAAAAADB34!&amp;rf=viewer_4" alt=""></p>
<p>分析一下 Sqoop 数据导入流程，首先用户输入一个 Sqoop import 命令，Sqoop 会从关系型数据库中获取元数据信息，比如要操作数据库表的 schema是什么样子，这个表有哪些字段，这些字段都是什么数据类型等。它获取这些信息之后，会将输入命令转化为基于 Map 的 MapReduce作业。这样 MapReduce作业中有很多 Map 任务，每个 Map 任务从数据库中读取一片数据，这样多个 Map 任务实现并发的拷贝，把整个数据快速的拷贝到 HDFS 上。 </p>
<p>Sqoop 如何使用命令行来导入数据的，其命令行语法如下所示。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">--connect jdbc:mysql://db.haoyuan.net:3306/djtdb_hadoop \</span><br><span class="line">--username sqoop \</span><br><span class="line">--password sqoop \</span><br><span class="line">--table user \</span><br><span class="line">--target-dir /junior/sqoop/ \       //可选，不指定目录，数据默认导入到/user下</span><br><span class="line">--where &quot;sex=&apos;female&apos;&quot; \    //可选</span><br><span class="line">--as-sequencefile \     //可选，不指定格式，数据格式默认为 Text 文本格式</span><br><span class="line">--num-mappers 10 \      //可选，这个数值不宜太大</span><br><span class="line">--null-string &apos;\\N&apos; \       //可选 </span><br><span class="line">--null-non-string &apos;\\N&apos; \       //可选 </span><br><span class="line">--connect：指定 JDBC URL。</span><br><span class="line">--username/password：mysql 数据库的用户名。</span><br><span class="line">--table：要读取的数据库表。</span><br><span class="line">--target-dir：将数据导入到指定的 HDFS 目录下，文件名称如果不指定的话，会默认数据库的表名称。 </span><br><span class="line">--where：过滤从数据库中要导入的数据。</span><br><span class="line">--as-sequencefile：指定数据导入数据格式。</span><br><span class="line">--num-mappers：指定 Map 任务的并发度。</span><br><span class="line">--null-string，--null-non-string：同时使用可以将数据库中的空字段转化为&apos;\N&apos;，因为数据库中字段为 null，会占用很大的空间。</span><br></pre></td></tr></table></figure>
<p>介绍几种 Sqoop 数据导入的特殊应用。</p>
<p>1、Sqoop 每次导入数据的时候，不需要把以往的所有数据重新导入 HDFS，只需要把新增的数据导入 HDFS 即可，下面我们来看看如何导入新增数据。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">--connect jdbc:mysql://db.haoyuan.net:3306/djtdb_hadoop \</span><br><span class="line">--username sqoop \</span><br><span class="line">--password sqoop \</span><br><span class="line">--table user \</span><br><span class="line"></span><br><span class="line">####解释####</span><br><span class="line"></span><br><span class="line">--incremental append \      //代表只导入增量数据</span><br><span class="line">--check-column id \         //以主键id作为判断条件</span><br><span class="line">--last-value 999        //导入id大于999的新增数据</span><br><span class="line">上述三个组合使用，可以实现数据的增量导入。</span><br></pre></td></tr></table></figure>
<p>2、Sqoop 数据导入过程中，直接输入明码存在安全隐患，我们可以通过下面两种方式规避这种风险。 </p>
<p>2、Sqoop 数据导入过程中，直接输入明码存在安全隐患，我们可以通过下面两种方式规避这种风险。<br>　　 1)-P:sqoop 命令行最后使用 -P，此时提示用户输入密码，而且用户输入的密码是看不见的，起到安全保护作用。密码输入正确后，才会执行 sqoop 命令。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">--connect jdbc:mysql://db.haoyuan.net:3306/djtdb_hadoop \</span><br><span class="line">--username sqoop \</span><br><span class="line">--table user \</span><br><span class="line">-P</span><br></pre></td></tr></table></figure>
<p>​    2)–password-file：指定一个密码保存文件，读取密码。我们可以将这个文件设置为只有自己可读的文件，防止密码泄露。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">--connect jdbc:mysql://db.haoyuan.net:3306/csdb_hadoop \</span><br><span class="line">--username sqoop \</span><br><span class="line">--table user \</span><br><span class="line">--password-file my-sqoop-password</span><br></pre></td></tr></table></figure>
<p><strong>Sqoop export</strong> </p>
<p>　　 它的功能是将数据从 HDFS 导入关系型数据库表中，其流程图如下所示。 </p>
<p><img src="http://a3.qpic.cn/psb?/V11T2YKt1pMnWZ/DfkNHY8ZvkSAbOlxsygkPWJaE65Kpf9sTycKyW4nL4Y!/b/dLAAAAAAAAAA&amp;bo=2gGeAQAAAAADB2Y!&amp;rf=viewer_4" alt=""></p>
<p>​    来分析一下 Sqoop 数据导出流程，首先用户输入一个 Sqoop export 命令，它会获取关系型数据库的 schema，建立 Hadoop 字段与数据库表字段的映射关系。 然后会将输入命令转化为基于 Map 的 MapReduce作业，这样 MapReduce作业中有很多 Map 任务，它们并行的从 HDFS 读取数据，并将整个数据拷贝到数据库中。　　 </p>
<p>我们来分析一下 Sqoop 数据导出流程，首先用户输入一个 Sqoop export 命令，它会获取关系型数据库的 schema，建立 Hadoop 字段与数据库表字段的映射关系。 然后会将输入命令转化为基于 Map 的 MapReduce作业，这样 MapReduce作业中有很多 Map 任务，它们并行的从 HDFS 读取数据，并将整个数据拷贝到数据库中。　　<br>　　 下面我们看一下 Sqoop 如何使用命令行来导出数据的，其命令行语法如下所示。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">sqoop export \</span><br><span class="line">--connect jdbc:mysql://db.haoyuan.net:3306/csdb_hadoop \</span><br><span class="line">--username sqoop \</span><br><span class="line">--password sqoop \</span><br><span class="line">--table user \</span><br><span class="line">--export-dir user</span><br><span class="line"></span><br><span class="line">####解释####</span><br><span class="line"></span><br><span class="line">--connect：指定 JDBC URL。</span><br><span class="line">--username/password：mysql 数据库的用户名和密码。</span><br><span class="line">--table：要导入的数据库表。</span><br><span class="line">--export-dir：数据在 HDFS 上的存放目录。</span><br></pre></td></tr></table></figure>
<p>下面我们介绍几种 Sqoop 数据导出的特殊应用。<br>　　 1、Sqoop export 将数据导入数据库，一般情况下是一条一条导入的，这样导入的效率非常低。这时我们可以使用 Sqoop export 的批量导入提高效率，其具体语法如下。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">sqoop export \</span><br><span class="line">--Dsqoop.export.records.per.statement=10 \</span><br><span class="line">--connect jdbc:mysql://db.haoyuan.net:3306/csdb_hadoop \</span><br><span class="line">--username sqoop \</span><br><span class="line">--password sqoop \</span><br><span class="line">--table user \</span><br><span class="line">--export-dir user \</span><br><span class="line">--batch</span><br><span class="line"></span><br><span class="line">####解释####</span><br><span class="line"></span><br><span class="line">--Dsqoop.export.records.per.statement：指定每次导入10条数据，--batch：指定是批量导入。</span><br></pre></td></tr></table></figure>
<p>​     2、 在实际应用中还存在这样一个问题，比如导入数据的时候，Map Task 执行失败， 那么该 Map 任务会转移到另外一个节点执行重新运行，这时候之前导入的数据又要重新导入一份，造成数据重复导入。 因为 Map Task 没有回滚策略，一旦运行失败，已经导入数据库中的数据就无法恢复。Sqoop export 提供了一种机制能保证原子性， 使用–staging-table 选项指定临时导入的表。Sqoop export 导出数据的时候会分为两步：第一步，将数据导入数据库中的临时表，如果导入期间 Map Task 失败，会删除临时表数据重新导入；第二步，确认所有 Map Task 任务成功后，会将临时表名称为指定的表名称。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sqoop export \</span><br><span class="line">--connect jdbc:mysql://db.haoyuan.net:3306/csdb_hadoop \</span><br><span class="line">--username sqoop \</span><br><span class="line">--password sqoop \</span><br><span class="line">--table user \</span><br><span class="line">--staging-table staging_user</span><br></pre></td></tr></table></figure>
<p>3、在 Sqoop 导出数据过程中，如果我们想更新已有数据，可以采取以下两种方式。<br>　　 1)通过 –update-key id 更新已有数据。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sqoop export \</span><br><span class="line">--connect jdbc:mysql://db.haoyuan.net:3306/csdb_hadoop \</span><br><span class="line">--username sqoop \</span><br><span class="line">--password sqoop \</span><br><span class="line">--table user \</span><br><span class="line">--update-key id</span><br></pre></td></tr></table></figure>
<pre><code>2)使用 –update-key id和–update-mode allowinsert 两个选项的情况下，如果数据已经存在，则更新数据，如果数据不存在，则插入新数据记录。
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sqoop export \</span><br><span class="line">--connect jdbc:mysql://db.haoyuan.net:3306/csdb_hadoop \</span><br><span class="line">--username sqoop \</span><br><span class="line">--password sqoop \</span><br><span class="line">--table user \</span><br><span class="line">--update-key id \</span><br><span class="line">--update-mode allowinsert</span><br></pre></td></tr></table></figure>
<p>4、如果 HDFS 中的数据量比较大，很多字段并不需要，我们可以使用 –columns 来指定插入某几列数据。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sqoop export \</span><br><span class="line">--connect jdbc:mysql://db.haoyuan.net:3306/csdb_hadoop \</span><br><span class="line">--username sqoop \</span><br><span class="line">--password sqoop \</span><br><span class="line">--table user \</span><br><span class="line">--column username,sex</span><br></pre></td></tr></table></figure>
<p>5、当导入的字段数据不存在或者为null的时候，我们使用–input-null-string和–input-null-non-string 来处理。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sqoop export \</span><br><span class="line">--connect jdbc:mysql://db.haoyuan.net:3306/csdb_hadoop \</span><br><span class="line">--username sqoop \</span><br><span class="line">--password sqoop \</span><br><span class="line">--table user \</span><br><span class="line">--input-null-string &apos;\\N&apos; \</span><br><span class="line">--input-null-non-string &apos;\\N&apos;</span><br></pre></td></tr></table></figure>
<p><strong>Sqoop与其它系统结合</strong></p>
<p>Sqoop 也可以与Hive、HBase等系统结合，实现数据的导入和导出，用户需要在 sqoop-env.sh 中添加HBASE_HOME、HIVE_HOME等环境变量。</p>
<p>1、Sqoop与Hive结合比较简单，使用 –hive-import 选项就可以实现。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">--connect jdbc:mysql://db.haoyuan.net:3306/csdb_hadoop \</span><br><span class="line">--username sqoop \</span><br><span class="line">--password sqoop \</span><br><span class="line">--table user \</span><br><span class="line">--hive-import</span><br></pre></td></tr></table></figure>
<p>2、Sqoop与HBase结合稍微麻烦一些，需要使用 –hbase-table 指定表名称，使用 –column-family 指定列名称。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">--connect jdbc:mysql://db.haoyuan.net:3306/csdb_hadoop \</span><br><span class="line">--username sqoop \</span><br><span class="line">--password sqoop \</span><br><span class="line">--table user \</span><br><span class="line">--hbase-table user \</span><br><span class="line">--column-family city</span><br></pre></td></tr></table></figure>
<h2 id="Sqoop-的安装步骤"><a href="#Sqoop-的安装步骤" class="headerlink" title="Sqoop 的安装步骤"></a>Sqoop 的安装步骤</h2><p>​    我的Hadoop 集群安装的是 Hadoop 2.7.2 版本，所以 Sqoop 安装版本也要与之相匹配，否则后面 Sqoop 工具的使用会出现问题。这里我们选择 sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz版本安装。 安装 Sqoop 很简单，分为以下几步完成。 </p>
<p>​    1、首先将下载的 sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz放到 /usr/java/目录下，然后对安装包解压、修改文件名和修改用户权限。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@yun05 soft]# tar zxvf sqoop-1.4.6.bin__hadoop-1.0.0.tar.gz //解压</span><br><span class="line">[root@yun05 soft]# rm sqoop-1.4.6.bin__hadoop-1.0.0.tar.gz //删除安装包</span><br><span class="line">[root@yun05 soft]# mv sqoop-1.4.6.bin__hadoop-1.0.0 sqoop //修改安装文件目录</span><br><span class="line">[root@yun05 soft]# chown -R hadoop:hadoop sqoop //赋予sqoop hadoop用户权限</span><br></pre></td></tr></table></figure>
<p>​    2、切换到/sqoop/conf 目录下，执行以下命令。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@yun05 soft]$ cd sqoop/conf</span><br><span class="line">[root@yun05 conf]$ mv sqoop-env-template.sh sqoop-env.sh</span><br></pre></td></tr></table></figure>
<p>​    3、然后使用 vi sqoop-env.sh 命令，打开文件添加如下内容。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#Set path to where bin/hadoop is available</span><br><span class="line">export HADOOP_COMMON_HOME=/usr/java/hadoop-2.2.0-x64</span><br><span class="line">#Set path to where hadoop-*-core.jar is available</span><br><span class="line">export HADOOP_MAPRED_HOME=/usr/java/hadoop-2.2.0-x64</span><br><span class="line">#set the path to where bin/hbase is available</span><br><span class="line">#export HBASE_HOME=</span><br><span class="line">#Set the path to where bin/hive is available</span><br><span class="line">export HIVE_HOME=/usr/java/hive-1.0.0</span><br><span class="line">#Set the path for where zookeper config dir is</span><br><span class="line">#export ZOOCFGDIR=</span><br></pre></td></tr></table></figure>
<p>​    如果数据读取不涉及hbase和hive，那么相关hbase和hive的配置可以不加；如果集群有独立的zookeeper集群，那么配置zookeeper，反之，不用配置。</p>
<p>​    4、 将相关的驱动 jar 包拷贝到 sqoop/lib 目录下。安装 Hadoop2.2.0 的核心 jar包有三个需要导入：commons-cli-1.2.jar、hadoop-common-2.2.0.jar和hadoop- mapreduce-client-core-2.2.0.jar。 数据库驱动 jar 包需要导入，这里我们使用的是 mysql 数据库，所以需要导入mysql-connector-java-5.1.21.jar包。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@yun05 lib]$ cp commons-cli-1.2.jar /usr/java/sqoop/lib</span><br><span class="line">[root@yun05 common]$ cp hadoop-common-2.2.0.jar /usr/java/sqoop/lib</span><br><span class="line">[root@yun05 mapreduce]$ cp hadoop-mapreduce-client-core-2.2.0.jar /usr/java/sqoop/lib</span><br><span class="line">[root@yun05 java]$ cp mysql-connector-java-5.1.21.jar /usr/java/sqoop/lib</span><br></pre></td></tr></table></figure>
<p>5、添加环境变量。</p>
<p>vi /etc/profile</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PATH=$PATH:$HOME/bin</span><br><span class="line">export SQOOP_HOME=/usr/java/sqoop //sqoop安装目录</span><br><span class="line">export PATH=$PATH:$SQOOP_HOME/bin</span><br></pre></td></tr></table></figure>
<p>环境添加完毕后，执行以下命令使环境生效。</p>
<p>source /etc/profile</p>
<p>6、测试运行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@yun05 config]$ sqoop list-databases \</span><br><span class="line">&gt; --connect jdbc:mysql://db.haoyuan.net:3306/djtdb_hadoop \</span><br><span class="line">&gt; --username sqoop \</span><br><span class="line">&gt; --password sqoop</span><br><span class="line">15/06/03 02:47:27 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6</span><br><span class="line">15/06/03 02:47:27 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.</span><br><span class="line">15/06/03 02:47:28 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.</span><br><span class="line">information_schema</span><br></pre></td></tr></table></figure>
<p>sqoop 命令执行成功，代表安装成功。</p>
<p>7、sqoop 使用</p>
<p>第一类：数据库中的数据导入到HDFS上</p>
<pre><code>sqoop import --connect jdbc:mysql://192.168.1.205:3306/db --username root --password 123  --table trade_detail --columns &apos;id, account, income, expenses&apos;
</code></pre><p>指定输出路径、指定数据分隔符</p>
<pre><code>sqoop import --connect jdbc:mysql://192.168.1.205:3306/db --username root --password 123  --table trade_detail --target-dir &apos;/sqoop/td&apos; --fields-terminated-by &apos;\t&apos;
</code></pre><p>指定Map数量 -m </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop import --connect jdbc:mysql://192.168.1.205:3306/db --username root --password 123  --table trade_detail --target-dir &apos;/sqoop/td1&apos; --fields-terminated-by &apos;\t&apos; -m 2</span><br></pre></td></tr></table></figure>
<p>增加where条件, 注意：条件必须用引号引起来</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop import --connect jdbc:mysql://192.168.1.205:3306/db --username root --password 123  --table trade_detail --where &apos;id&gt;3&apos; --target-dir &apos;/sqoop/td2&apos;</span><br></pre></td></tr></table></figure>
<p>增加query语句(使用 \ 将语句换行)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop import --connect jdbc:mysql://192.168.1.205:3306/db --username root --password 123 \</span><br></pre></td></tr></table></figure>
<p>​    </p>
<p>​    注意：如果使用–query这个命令的时候，需要注意的是where后面的参数，AND $CONDITIONS这个参数必须加上，而且存在单引号与双引号的区别，如果–query后面使用的是双引号，那么需要在$CONDITIONS前加上\即\$CONDITIONS</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--query &apos;SELECT * FROM trade_detail where id &gt; 2 AND $CONDITIONS&apos; --split-by trade_detail.id --target-dir &apos;/sqoop/td3&apos;</span><br></pre></td></tr></table></figure>
<p>第二类：将HDFS上的数据导出到数据库中(不要忘记指定分隔符)</p>
<pre><code>sqoop export --connect jdbc:mysql://192.168.1.205:3306/db --username root --password 123 --export-dir &apos;/td3&apos; --table td_bak -m 1 --fields-terminated-by &apos;,&apos;
</code></pre><p>4.配置mysql远程连接<br>    GRANT ALL PRIVILEGES ON db.<em> TO ‘root’@’192.168.1.205’ IDENTIFIED BY ‘123’ WITH GRANT OPTION;<br>    FLUSH PRIVILEGES;<br>    GRANT ALL PRIVILEGES ON </em>.* TO ‘root’@’%’ IDENTIFIED BY ‘123’ WITH GRANT OPTION;</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/sqoop/">sqoop</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-hadoop 2.7.2集群搭建(前期准备)" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/06/23/hadoop 2.7.2集群搭建(前期准备)/" class="article-date">
      <time datetime="2016-06-23T03:17:15.000Z" itemprop="datePublished">2016-06-23</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/06/23/hadoop 2.7.2集群搭建(前期准备)/">hadoop 2.7.2集群搭建(前期准备)</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h3 id="修改Linux主机名"><a href="#修改Linux主机名" class="headerlink" title="修改Linux主机名"></a>修改Linux主机名</h3><p>修改/etc/sysconfig/network中的hostname</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/sysconfig/network</span><br><span class="line">HOSTNAME=localhost.localdomain  #修改localhost.localdomain为yun01(自己主机的名字)</span><br></pre></td></tr></table></figure>
<p>修改network的HOSTNAME项。点前面是主机名，点后面是域名。没有点就是主机名。</p>
<p>这个是永久修改，重启后生效。</p>
<p>修改/etc/hosts文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/hosts</span><br><span class="line"></span><br><span class="line">127.0.0.1    localhost.localdomain  #修改localhost.localdomain为yun01(自己主机的名字)</span><br><span class="line">shutdown -r now</span><br></pre></td></tr></table></figure>
<p>最后，重启服务器即可</p>
<h3 id="linux-CentOS命令行永久修改IP地址、网关、DNS"><a href="#linux-CentOS命令行永久修改IP地址、网关、DNS" class="headerlink" title="linux CentOS命令行永久修改IP地址、网关、DNS"></a>linux CentOS命令行永久修改IP地址、网关、DNS</h3><h4 id="设置IP"><a href="#设置IP" class="headerlink" title="设置IP"></a>设置IP</h4><p><strong>[root@localhost etc]# vi /etc/sysconfig/network-scripts/ifcfg-eth0</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">DEVICE=eth0</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">ONBOOT=yes</span><br><span class="line">HWADDR=00:16:36:66:a3:ec </span><br><span class="line">IPADDR=10.0.0.11</span><br><span class="line">NETMASK=255.255.255.0</span><br><span class="line">GATEWAY=10.0.0.1</span><br><span class="line">TYPE=Ethernet</span><br><span class="line">USERCTL=no</span><br><span class="line">IPV6INIT=no</span><br><span class="line">PEERDNS=yes</span><br><span class="line"></span><br><span class="line">###########解释###########</span><br><span class="line">1.BOOTPROTO=static 就是手动设置静态IP，不需要自动获取(static/dhcp/bootp)</span><br><span class="line">2.USERCTL=no     不允许非root用户控制该设备</span><br><span class="line">3.PEERDNS=no     不修改/etc/resolv.conf(如果使用DHCP，则yes是默认选项)</span><br><span class="line">4.TYPE=Ethernet 类型以太网</span><br><span class="line">5.GATEWAY 网关</span><br><span class="line">6.NETMASK 掩码</span><br><span class="line">7.ONBOOT=yes 开机重启会自动加载</span><br><span class="line">Red Hat中没有提供缺省的/etc/resolv.conf文件，它的内容是根据在安装时给出的选项动态创建的。</span><br></pre></td></tr></table></figure>
<h4 id="修改网关"><a href="#修改网关" class="headerlink" title="修改网关"></a>修改网关</h4><p><strong>vim /etc/sysconfig/network</strong></p>
<p>增加一条网关信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GATEWAY=192.168.1.1</span><br></pre></td></tr></table></figure>
<h4 id="修改DNS"><a href="#修改DNS" class="headerlink" title="修改DNS"></a>修改DNS</h4><p><strong>vim /etc/resolv.conf</strong></p>
<p>增加DNS信息即可</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nameserver 192.168.1.1</span><br></pre></td></tr></table></figure>
<h4 id="重新加载网络配置"><a href="#重新加载网络配置" class="headerlink" title="重新加载网络配置"></a>重新加载网络配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/network restart</span><br></pre></td></tr></table></figure>
<h3 id="修改主机名和IP的映射关系"><a href="#修改主机名和IP的映射关系" class="headerlink" title="修改主机名和IP的映射关系"></a>修改主机名和IP的映射关系</h3><p><strong>vi /etc/hosts</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">192.168.1.201	yun01</span><br><span class="line">192.168.1.201	yun02</span><br><span class="line">192.168.1.201	yun03</span><br><span class="line">192.168.1.201	yun04</span><br><span class="line">192.168.1.201	yun05</span><br><span class="line">192.168.1.201	yun06</span><br><span class="line">192.168.1.201	yun07</span><br><span class="line">……</span><br></pre></td></tr></table></figure>
<p>你的集群要用几个主机搭建，就配置几个主机ip地址</p>
<h3 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h3><h4 id="查看iptables和SElinux状态："><a href="#查看iptables和SElinux状态：" class="headerlink" title="查看iptables和SElinux状态："></a>查看iptables和SElinux状态：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">service iptables status</span><br><span class="line">getenforce</span><br></pre></td></tr></table></figure>
<h4 id="关闭iptables和SElinux："><a href="#关闭iptables和SElinux：" class="headerlink" title="关闭iptables和SElinux："></a>关闭iptables和SElinux：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">service iptables stop   #临时关闭防火墙</span><br><span class="line">chkconfig iptables off    #永久关闭防火墙，开机不自启动，想自启动改成on</span><br><span class="line">setenforce 0    #临时关闭SElinux,临时打开SElinux状态命令：setenforce 1</span><br></pre></td></tr></table></figure>
<h4 id="永久关闭SElinux"><a href="#永久关闭SElinux" class="headerlink" title="永久关闭SElinux"></a>永久关闭SElinux</h4><p><strong>vim /etc/selinux/config</strong>,然后将SELINUX改成<strong>disabled</strong>，这样即使重启操作系统SElinux也是关闭状态。</p>
<h4 id="查看SElinux状态："><a href="#查看SElinux状态：" class="headerlink" title="查看SElinux状态："></a>查看SElinux状态：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/sbin/sestatus -v</span><br></pre></td></tr></table></figure>
<h3 id="配置ssh免登陆"><a href="#配置ssh免登陆" class="headerlink" title="配置ssh免登陆"></a>配置ssh免登陆</h3><p>生成ssh免登陆密钥，进入到我的home目录下的.ssh文件夹</p>
<pre><code>cd ~/.ssh
</code></pre><p>开始生成私钥和公钥</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa （然后直接敲四个回车）</span><br></pre></td></tr></table></figure>
<p>执行完这个命令后，会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）<br>将公钥拷贝到要免登陆的机器上</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id localhost(你配置的主机名或者ip地址)</span><br></pre></td></tr></table></figure>
<h3 id="安装idk，配置环境变量"><a href="#安装idk，配置环境变量" class="headerlink" title="安装idk，配置环境变量"></a>安装idk，配置环境变量</h3><p>安装JDK</p>
<p>将 <strong>jdk-8u92-linux-x64.tar.gz</strong>上传到Linux 的 <strong>/</strong> 根目录下</p>
<p>解压jdk</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#创建文件夹</span><br><span class="line">mkdir /usr/java</span><br><span class="line">#解压</span><br><span class="line">tar -zxvf jdk-8u92-linux-x64.tar.gz -C /usr/java</span><br><span class="line">#修改解压后jdk的名字</span><br><span class="line">cd /usr/java</span><br><span class="line">mv jdk-8u_92-i585/ jdk1.8</span><br></pre></td></tr></table></figure>
<p>将java添加到环境变量中</p>
<pre><code>vim /etc/profile

#在文件最后添加
export JAVA_HOME=/usr/java/jdk1.8
export PATH=$PATH:$JAVA_HOME/bin

#刷新配置
source /etc/profile
</code></pre>
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hadoop-2-7-2-前期准备/">hadoop 2.7.2 前期准备</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-计算机基础及Linux入门" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/06/18/计算机基础及Linux入门/" class="article-date">
      <time datetime="2016-06-18T13:42:01.000Z" itemprop="datePublished">2016-06-18</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/06/18/计算机基础及Linux入门/">计算机基础及linux入门</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h4 id="计算机是-电子数字计算机的简称。"><a href="#计算机是-电子数字计算机的简称。" class="headerlink" title="计算机是 电子数字计算机的简称。"></a>计算机是 电子数字计算机的简称。</h4><p>程序和数据 成为计算机软件。</p>
<p>pc服务器：1U=4.445cm</p>
<p>互联网企业都用戴尔服务器。其次 惠普、IBM</p>
<p>BIOS芯片 主板通电后各部件自检，设置，保存，一切正常后才能启动操作系统。记录了电脑最基本的信息，是软件与硬件打交道的最基础的桥梁。</p>
<p>硬盘未来是调优的关键点，硬盘的性能是决定网站的新年能的重要因素。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">磁盘和内存的优化：</span><br><span class="line">1、内存临时储存用户的数据，然后再写到disk中。（门户网站）</span><br><span class="line">     1）速度快     2）丢数据</span><br><span class="line">2、写时：用户数据写到disk中，读时：数据再读到内存中再发给用户。 （并发量不大的中小企业）</span><br><span class="line">     1）性能低     2）不丢数据</span><br></pre></td></tr></table></figure>
<h4 id="生产中的硬件应用小结"><a href="#生产中的硬件应用小结" class="headerlink" title="生产中的硬件应用小结"></a>生产中的硬件应用小结</h4><h5 id="1、PC服务器"><a href="#1、PC服务器" class="headerlink" title="1、PC服务器"></a>1、PC服务器</h5><p>互联网公司，品牌DELL，HP，IBM。</p>
<p>Dell品牌：2010年以前 1U的1850 1950，2U的2850 2950</p>
<p>2010到2014：1U的R410/420 R610/620</p>
<p>IBM： 2U的3750/3850/3950s</p>
<h6 id="2、内存"><a href="#2、内存" class="headerlink" title="2、内存"></a>2、内存</h6><p>进程：运行着的程序，进程会放在内存里。</p>
<p>程序：静态的，在磁盘里。</p>
<h5 id="企业案例："><a href="#企业案例：" class="headerlink" title="企业案例："></a>企业案例：</h5><h6 id="1）、门户极端案例："><a href="#1）、门户极端案例：" class="headerlink" title="1）、门户极端案例："></a>1）、门户极端案例：</h6><p>高并发，大数据量：会把数据先写到内存，然后在定时或者定量的写到磁盘，最终还是会加载到内存。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">特点：</span><br><span class="line">a、高并发的写入性能高。</span><br><span class="line">b、可能会丢失一部分在内存中还没来得及存入磁盘的数据。</span><br></pre></td></tr></table></figure>
<h6 id="2）、中小企业案例："><a href="#2）、中小企业案例：" class="headerlink" title="2）、中小企业案例："></a>2）、中小企业案例：</h6><p>并发不是很大网站，会先把数据存放到磁盘，然后通过程序吧数据读入到内存里，再对外提供访问服务.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">由于90%的是网站都是读取为主，写入为辅，读写比例10：1，所以并发写入不是问题。</span><br><span class="line">提醒：这里的内存和硬盘，可能是多台机器组成的。</span><br></pre></td></tr></table></figure>
<h5 id="3、磁盘"><a href="#3、磁盘" class="headerlink" title="3、磁盘"></a>3、磁盘</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">磁盘接口：SAS SATA（这两个都是机械硬盘） SSD（固态硬盘）</span><br><span class="line">性能：SSD&gt;SATA&gt;SAS，</span><br><span class="line">应用：常规工作场景选SAS（转速15K）；</span><br><span class="line">          SATA（转速7.2K-1W）线下的备份；</span><br><span class="line">          高并发SSD。</span><br><span class="line">淘宝网：SATA和SSD混合起来用。</span><br></pre></td></tr></table></figure>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
    </nav>
  
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2016 原豪
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="A fast, simple &amp; powerful blog framework">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="Another simple and elegant theme for Hexo  v3.5">Yelee</a> by MOxFIVE <i class="fa fa-heart animated infinite pulse"></i>
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" >Site Visitors: 
                            <span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>, </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit">Page Hits: 
                            <span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 5;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>




<div class="scroll" id="scroll">
    <a href="#" title="Back to Top"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="Comments"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="Go to Bottom"><i class="fa fa-arrow-down"></i></a>
</div>
<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>